{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e2a137-07bc-4053-b906-4aaefc84b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa1ca34-ac7b-413a-8aca-433b91c46262",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIST STEPS, Ingest will alwasys be the first step.  IF NONE or CLOSED, then there is no next step\n",
    "STEPS = [\"INGEST\", \"PROCESSING\", \"ASSIGNED\", \"WORKING\", \"PENDING_APPROVAL\", \"APPROVED\", \"CLOSED\", \"NONE\"]\n",
    "NEXT, TMIN, TRNG, PROB = \"NEXT_STEPS\", \"TIME_MIN\", \"TIME_RANGE\", \"PROBABILITY\"\n",
    "\n",
    "## Build a map of all the STEPS, the next steps possible, time between steps\n",
    "STEP_MAP = {\n",
    "    STEPS[0]: {\n",
    "        NEXT: [STEPS[1], STEPS[7]],\n",
    "        TMIN: [1,   -1],\n",
    "        TRNG: [120, -1],\n",
    "        PROB: [.3,   1],\n",
    "    },\n",
    "    STEPS[1]: {\n",
    "        NEXT: [STEPS[0], STEPS[1], STEPS[2], STEPS[3], STEPS[7]],\n",
    "        TMIN: [1,        120,      200,      360,      -1],\n",
    "        TRNG: [1200,     180,      360,      360,      -1],\n",
    "        PROB: [.1,       .2,       .5,       .8,        1],\n",
    "    },\n",
    "    STEPS[2]: {\n",
    "        NEXT: [STEPS[0], STEPS[1], STEPS[2], STEPS[3], STEPS[7]],\n",
    "        TMIN: [120,      200,      200,      120,      -1],\n",
    "        TRNG: [1200,     300,      360,      620,      -1],\n",
    "        PROB: [.03,      .06,      .09,      .6,        1],\n",
    "    },\n",
    "    STEPS[3]: {\n",
    "        NEXT: [STEPS[0], STEPS[3], STEPS[4], STEPS[5], STEPS[7]],\n",
    "        TMIN: [120,      300,      600,      1200,     -1],\n",
    "        TRNG: [1200,     300,      600,      6200,     -1],\n",
    "        PROB: [.03,      .06,      .9,      .95,        1],\n",
    "    },\n",
    "    STEPS[4]: {\n",
    "        NEXT: [STEPS[0], STEPS[4], STEPS[5], STEPS[6], STEPS[7]],\n",
    "        TMIN: [120,      120,      480,      1200,     -1],\n",
    "        TRNG: [1200,     300,      900,      6200,     -1],\n",
    "        PROB: [.03,      .06,      .9,      .91,        1],\n",
    "    },\n",
    "    STEPS[5]: {\n",
    "        NEXT: [STEPS[0], STEPS[1], STEPS[5], STEPS[6], STEPS[7]],\n",
    "        TMIN: [120,      120,      30,       1200,     -1],\n",
    "        TRNG: [1200,     300,      900,      6200,     -1],\n",
    "        PROB: [.03,      .12,      .15,      .93,        1],\n",
    "    },\n",
    "    STEPS[6]: { NEXT: [], TMIN: [], TRNG: [], PROB: [], },\n",
    "    STEPS[7]: { NEXT: [], TMIN: [], TRNG: [], PROB: [], },\n",
    "}\n",
    "\n",
    "def create_example_datasheet(ids=None, timestamps=None):\n",
    "    if ids is None or timestamps is None:\n",
    "        raise Exception(\"Error: need to pass and array of ids and timestamps\")\n",
    "    if len(ids) != len(timestamps):\n",
    "        raise Exception(\"Error: the number of ids and timestamps, must be identical\")\n",
    "    \n",
    "    ## Take the steps below and generate some random data\n",
    "    id_col, step_col, tmp_col = \"id_col\", \"step_col\", \"tmp_col\"\n",
    "    data = {\n",
    "        id_col: [], step_col: [], tmp_col: [],\n",
    "    }\n",
    "\n",
    "    ## Loop through all the entries in the df,\n",
    "    for i in range(len(ids)): #range(5): #\n",
    "        idx = ids[i]\n",
    "        tmpstp = timestamps[i]\n",
    "\n",
    "        ## if there was a transfer2 timestamp\n",
    "        if tmpstp is not None:\n",
    "            nxt_step = STEPS[0]\n",
    "            nxt_tmStp = tmpstp + datetime.timedelta(0, random.randrange(15)) ## Increment our timestamp\n",
    "\n",
    "            ## While our next_step doesn't equal Close or None\n",
    "            while nxt_step != STEPS[6] and nxt_step != STEPS[7]:\n",
    "                data[id_col].append(idx)\n",
    "                data[step_col].append(nxt_step)\n",
    "                data[tmp_col].append(nxt_tmStp)\n",
    "\n",
    "                cur_step = nxt_step\n",
    "                rnd_vle = random.random()\n",
    "\n",
    "                for j in range(len(STEP_MAP[nxt_step][PROB])):\n",
    "                    if rnd_vle <= STEP_MAP[nxt_step][PROB][j]:\n",
    "                        nxt_step = STEP_MAP[nxt_step][NEXT][j]\n",
    "                        if nxt_step == STEPS[6] or nxt_step == STEPS[7]:\n",
    "                            break\n",
    "\n",
    "                        nxt_tmStp = nxt_tmStp + datetime.timedelta(0, random.randrange(STEP_MAP[nxt_step][TMIN][j], STEP_MAP[nxt_step][TMIN][j] + STEP_MAP[nxt_step][TRNG][j]))\n",
    "                        break\n",
    "\n",
    "            if nxt_step == STEPS[6]:\n",
    "                data[id_col].append(idx)\n",
    "                data[step_col].append(nxt_step)\n",
    "                data[tmp_col].append(nxt_tmStp)\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0acb4077-db32-48d5-a574-835e9a083d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_col</th>\n",
       "      <th>step_col</th>\n",
       "      <th>tmp_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>idx_0</td>\n",
       "      <td>INGEST</td>\n",
       "      <td>2024-10-27 17:52:48.378899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idx_1</td>\n",
       "      <td>INGEST</td>\n",
       "      <td>2024-10-27 18:01:23.378919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>idx_1</td>\n",
       "      <td>PROCESSING</td>\n",
       "      <td>2024-10-27 18:06:13.378919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>idx_2</td>\n",
       "      <td>INGEST</td>\n",
       "      <td>2024-10-27 17:49:39.378923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>idx_3</td>\n",
       "      <td>INGEST</td>\n",
       "      <td>2024-10-27 17:37:37.378926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_col    step_col                    tmp_col\n",
       "0  idx_0      INGEST 2024-10-27 17:52:48.378899\n",
       "1  idx_1      INGEST 2024-10-27 18:01:23.378919\n",
       "2  idx_1  PROCESSING 2024-10-27 18:06:13.378919\n",
       "3  idx_2      INGEST 2024-10-27 17:49:39.378923\n",
       "4  idx_3      INGEST 2024-10-27 17:37:37.378926"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generate a the timestamp and ids of our datapoints\n",
    "time_stamps_min, time_stamps_rng = datetime.timedelta(0, -3600 * 24 * 2), 3000\n",
    "ids, time_stamps = [], []\n",
    "for i in range(5000):\n",
    "    ids.append(f\"idx_{i}\")\n",
    "    time_stamps.append(datetime.datetime.now() + time_stamps_min + datetime.timedelta(0, random.randrange(time_stamps_rng)))\n",
    "\n",
    "## Create our example datasheet\n",
    "df_sys2 = create_example_datasheet(ids, time_stamps)\n",
    "## Write our dataframe out to a csv\n",
    "df_sys2.to_csv(\"sys_log-generated.csv\")\n",
    "df_sys2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c478e1a-85e9-4ebb-a933-1bc7831ccaef",
   "metadata": {},
   "source": [
    "### Take our generated system log and load it into gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b540b07-d749-44eb-b52c-9fc3a0b4ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_secret = \"<Put api key here>\"\n",
    "genai.configure(api_key=api_secret)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e097105c-16ba-411e-94b8-cc8dafa32797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myfile=genai.File({\n",
      "    'name': 'files/2rd5s2383ini',\n",
      "    'display_name': 'sys_log-generated.csv',\n",
      "    'mime_type': 'text/csv',\n",
      "    'sha256_hash': 'ZmVlMjE0NjhlZjc4MzEzNGQ2Y2U0NTg0ODBjNmUxYmI2ZGM3MzE4OTU0Y2EyMmIzNjA0ODM1YzM2NjE1ZmFlZg==',\n",
      "    'size_bytes': '528145',\n",
      "    'state': 'ACTIVE',\n",
      "    'uri': 'https://generativelanguage.googleapis.com/v1beta/files/2rd5s2383ini',\n",
      "    'create_time': '2024-10-29T17:31:00.633503Z',\n",
      "    'expiration_time': '2024-10-31T17:31:00.559335071Z',\n",
      "    'update_time': '2024-10-29T17:31:00.633503Z'})\n",
      "result.text=\"The file appears to contain data about the processing steps of various items, likely tasks or data entries, identified by unique `id_col` values. Here's a breakdown:\\n\\n* **id_col**: Represents a unique identifier for each item.  It seems like multiple steps can occur for the same `id_col`, indicating different stages in the processing workflow.\\n* **step_col**:  Defines the processing stage each item is currently in.  These stages seem to be:\\n    * **INGEST**: Initial stage where the item is received.\\n    * **PROCESSING**:  The item is being processed or handled.\\n    * **ASSIGNED**: The item has been assigned to a specific person or resource.\\n    * **WORKING**: The item is being actively worked on.\\n    * **PENDING_APPROVAL**: The item is awaiting approval.\\n    * **APPROVED**: The item has been approved.\\n    * **CLOSED**: The item is finished or complete.\\n    * **PENDING**:  Potentially another stage, though its meaning isn't entirely clear.\\n* **tmp_col**:  Likely represents timestamps indicating when each processing step occurred.\\n\\n**Example Interpretation:**\\n\\nLooking at `id_col` `idx_8`, we see the following steps:\\n\\n1. **INGEST** (2024-10-27 17:57:07.378943) - The item was received.\\n2. **PROCESSING** (2024-10-27 18:04:25.378943) - The item was being processed.\\n3. **ASSIGNED** (2024-10-27 18:10:27.378943) - The item was assigned to a person or resource.\\n4. **WORKING** (2024-10-27 18:37:07.378943) - The item was being actively worked on.\\n5. **WORKING** (2024-10-27 18:46:06.378943) - Continued working on the item.\\n6. **PENDING_APPROVAL** (2024-10-27 19:07:47.378943) - The item is awaiting approval.\\n7. **APPROVED** (2024-10-27 19:16:38.378943) - The item was approved.\\n\\nThis data could be useful for:\\n\\n* **Tracking workflow progress**:  Identifying bottlenecks or delays in the processing pipeline.\\n* **Analyzing task durations**:  Calculating how long each stage takes, on average.\\n* **Understanding resource utilization**:  Determining the workload assigned to different people or resources.\\n\\nIt would be helpful to know what specific system this data is related to for more precise analysis. \\n\"\n"
     ]
    }
   ],
   "source": [
    "myfile = genai.upload_file(\"./data/01-csv/sys_log-generated.csv\")\n",
    "print(f\"{myfile=}\")\n",
    "\n",
    "result = model.generate_content(\n",
    "    [myfile, \"\\n\\n\", \"Can you tell me about the contents of the file?\"]\n",
    ")\n",
    "print(f\"{result.text=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf1727-3017-4ce5-909c-b95e93e5f0a6",
   "metadata": {},
   "source": [
    "### Cache our task files and create a GenerativeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd684d8-569a-47e1-9222-9529fba3d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = caching.CachedContent.create(\n",
    "    model='models/gemini-1.5-flash-001',\n",
    "    display_name='./data/01-csv/sys_log-generated.csv', \n",
    "    system_instruction=(\n",
    "        'Review the file and answer questions regarding the descriptive statitics about it.'\n",
    "    ),\n",
    "    contents=[myfile],\n",
    "    ttl=datetime.timedelta(minutes=5),\n",
    ")\n",
    "\n",
    "model = genai.GenerativeModel.from_cached_content(cached_content=cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5876d375-65dc-4f4d-bcb8-7a9c93e2793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 442946\n",
      "candidates_token_count: 290\n",
      "total_token_count: 443236\n",
      "cached_content_token_count: 442917\n",
      "\n",
      " =========================== Results =========================== \n",
      "Let's analyze the data:\n",
      "\n",
      "**1. Unique IDs:**\n",
      "\n",
      "* There are **501 unique IDs** in the data. \n",
      "\n",
      "**2. Completed Tasks:**\n",
      "\n",
      "* A task is considered completed when it reaches the \"CLOSED\" status.\n",
      "* There are **291 completed tasks** in the data.\n",
      "\n",
      "**3. Average Time to Complete:**\n",
      "\n",
      "To calculate the average time from ingest to complete, we need to do the following:\n",
      "\n",
      "1. **Identify the Ingest Timestamp:** For each completed task, find the timestamp when the task entered the \"INGEST\" state.\n",
      "2. **Identify the Complete Timestamp:** For each completed task, find the timestamp when the task reached the \"CLOSED\" state.\n",
      "3. **Calculate the Duration:** Subtract the ingest timestamp from the complete timestamp to get the duration for each task.\n",
      "4. **Calculate the Average:** Sum the durations of all completed tasks and divide by the number of completed tasks.\n",
      "\n",
      "**Unfortunately, we can't directly calculate the average time to complete from the provided data.** The data only shows the timestamps when a task transitions to a new state. We lack information on when the task was initially ingested, making it impossible to determine the exact time it took from ingest to completion for each task. \n",
      "\n",
      "**To get the average time to completion, you would need a complete dataset that includes the initial ingest timestamp for every task.** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content([('How many unique ids are there?'), ('How many tasks are completed?'), ('For the completed tasks, what is the average time from ingest to complete?')])\n",
    "print(response.usage_metadata)\n",
    "print(\" =========================== Results =========================== \")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f2d80-02b9-4459-b2c8-2a1412b91876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
